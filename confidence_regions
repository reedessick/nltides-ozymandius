#!/usr/bin/env python

__usage__ = "confidence_regions [--options] samples.hdf5 [samples.hdf5 samples.hdf5 ...]"
__doc__ = "an executable that computes things"
__author__ = "reed.essick@ligo.org"

#-------------------------------------------------

import os
import numpy as np

from optparse import OptionParser

### non-standard libraries
from sddr import utils

#-------------------------------------------------

parser = OptionParser(usage=__usage__, description=__doc__)

parser.add_option('-v', '--verbose', default=False, action='store_true')
parser.add_option('-V', '--Verbose', default=False, action='store_true')

parser.add_option('', '--field', default=utils.DEFAULT_FIELD, type='string')
parser.add_option('', '--initial-burnin', default=utils.DEFAULT_INITIAL_BURNIN, type='int',
    help='force the code to skip the first --initial-burnin samples, and then proceed with --deltaLogP logic. \
DEFAULT=%d'%utils.DEFAULT_INITIAL_BURNIN)
parser.add_option('', '--deltaLogP', default=utils.DEFAULT_DELTALOGP, type='float',
    help='used when stripping burn-in from hdf5 files')
parser.add_option('', '--downsample', default=utils.DEFAULT_DOWNSAMPLE, type='int',
    help='only retain 1 out of every --downsample samples after stripping burn-in. Used when reading both file types')

parser.add_option('', '--upper', default=[], type='float', action='append',
    help='confidence levels for upper limits. e.g.: `--upper 0.9`. Can be repeated')
parser.add_option('', '--lower', default=[], type='float', action='append',
    help='confidence levels for lower limits. e.g.: `--lower 0.9`. Can be repeated')
parser.add_option('', '--greedy', default=[], type='float', action='append',
    help='confidence levels for greedy binned confidence regions. e.g.: `--greedy 0.9`. Can be repeated')

opts, args = parser.parse_args()
assert args, 'please supply at least 1 input argument\n%s'%__usage__

opts.verbose |= opts.Verbose

#-------------------------------------------------

### read in samples
samples = utils.load(args, field=opts.field, deltaLogP=opts.deltaLogP, downsample=opts.downsample, initial_burnin=opts.initial_burnin, verbose=opts.verbose)

#-------------------------------------------------

### generate limits
for upper in opts.upper:
    upper *= 100 # convert to precentile
    print('%s <= %.6e @ %.6e confidence'%(opts.field, np.percentile(samples, upper), upper))

for lower in opts.lower:
    lower *= 100
    print('%s >= %.6e @ %.6e confidence'%(opts.field, np.percentile(samples, lower), lower))

### generate confidence regions
N = len(samples)
samples.sort()
for greedy in opts.greedy:
    dn = int(np.ceil(N*greedy)) ### the number of samples required to reach at least this confidence level
    sizes = samples[dn:] - samples[:dn] ### the sizes of the candidate regions
    l = np.argmin(sizes)
    u = l + dn
    print('%.6e <= %s <= %s @ %.6e confidence'%(samples[l], field, samples[u], greedy))
